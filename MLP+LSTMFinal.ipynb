{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMyz7vkmtl/G27v38iDSUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedjialeuJordan/ceri-m1-techniques-de-test/blob/master/MLP%2BLSTMFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparation des données"
      ],
      "metadata": {
        "id": "9BmjfZ0rvWNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path=\"/content/protein-secondary-structure.train\"\n",
        "test_path=\"/content/protein-secondary-structure.test\"\n",
        "\n",
        "#afficher les 30 premières lignes de chaque fichier\n",
        "with open(train_path, 'r') as f:\n",
        "  train_lines = [next(f) for x in range(30)]\n",
        "with open(test_path, 'r') as f:\n",
        "  test_lines = [next(f) for x in range(30)]\n",
        "\n",
        "train_lines, test_lines"
      ],
      "metadata": {
        "id": "Uu5anz_NvV3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation du parsing"
      ],
      "metadata": {
        "id": "i0kdDGrXwT3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implémentation du parsing\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "def parse_protein_file(filepath: str) -> Tuple[List[str], List[str]]:\n",
        "    sequences = []\n",
        "    structures = []\n",
        "    current_seq = []\n",
        "    current_struct = []\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith('#'):\n",
        "                continue\n",
        "            if line == '<>':\n",
        "                if current_seq and current_struct:\n",
        "                    sequences.append(''.join(current_seq))\n",
        "                    structures.append(''.join(current_struct))\n",
        "                current_seq = []\n",
        "                current_struct = []\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                if len(parts) == 2:\n",
        "                    aa, ss = parts\n",
        "                    current_seq.append(aa)\n",
        "                    current_struct.append(ss if ss in \"hecHEC\" else 'c')  #'_' devient 'c'\n",
        "\n",
        "    # Ajout de la dernière séquence si nécessaire\n",
        "    if current_seq and current_struct:\n",
        "        sequences.append(''.join(current_seq))\n",
        "        structures.append(''.join(current_struct))\n",
        "\n",
        "    return sequences, structures\n",
        "\n",
        "# Appliquer au jeu de train\n",
        "train_sequences, train_labels = parse_protein_file(train_path)\n",
        "test_sequences, test_labels = parse_protein_file(test_path)\n",
        "\n",
        "# Affichez les 5 premières paires séquence / structure\n",
        "list(zip(train_sequences, train_labels))[:5]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xhf7Zfdsyrcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f660b3-8bbf-47fe-a53a-ab4b2b15574e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('GVGTVPMTDYGNDVEYYGQVTIGTPGKSFNLNFDTGSSNLWVGSVQCQASGCKGGRDKFNPSDGSTFKATGYDASIGYGDGSASGVLGYDTVQVGGIDVTGGPQIQLAQRLGGGGFPGDNDGLLGLGFDTLSITPQSSTNAFDQVSAQGKVIQPVFVVYLAASNISDGDFTMPGWIDNKYGGTLLNTNIDAGEGYWALNVTGATADSTYLGAIFQAILDTGTSLLILPDEAAVGNLVGFAGAQDAALGGFVIACTSAGFKSIPWSIYSAIFEIITALGNAEDDSGCTSGIGASSLGEAILGDQFLKQQYVVFDRDNGIRLAPVA',\n",
              "  'ccccccccccccccccccceecccccceecceeecccccceeccccccccccccccccccccccccccccccccccccccccceecccccccccccccccccccceeeeecccccccccccceeeccccccccccccccchhhhhhhccccccccccceeeccccceeecccccccccccccccccccccccccccceeccccccccccccccceecccccccceecccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccceechhhhccccceeeccceeeccccc'),\n",
              " ('AQCEATIESNDAMQYDLKEMVVDKSCKQFTVHLKHVGKMAKSVMGHNWVLTKEADKEGVATDGMNAGLAQDYVKAGDTRVIAHTKVIGGGESDSVTFDVSKLTPGEAYAYFCSFPGHWAMMKGTLKLSN',\n",
              "  'ccceeeeeeccccccccceeeeecccceeeeeeeeccccchhhhcccceeeeccchhhhhhhhhccccccccccccccccceecccccccceeeeeeeccccccccceeeecccccccccceeeeeeec'),\n",
              " ('SVDIQGNDQMQFNTNAITVDKSCKQFTVNLSHPGNLPKNVMGHNWVLSTAADMQGVVTDGMASGLDKDYLKPDDSRVIAHTKLIGSGEKDSVTFDVSKLKEGEQYMFFCTFPGHSALMKGTLTLK',\n",
              "  'ceeeeccccccccccceeeccccceeeeeeecccccccccccccceeeecccchhhhhhhhhhchhhhccccccccccccccccccccceeeeeeccccccccceeeecccccccccceeeeeec'),\n",
              " ('ALWQFNGMIKCKIPSSEPLLDFNNYGCYCGLGGSGTPVDDLDRCCQTHDNCYKQAKKLDSCKVLVDNPYTNNYSYSCSNNEITCSSENNACEAFICNCDRNAAICFSKVPYNKEHKNLDKKNC',\n",
              "  'chhhhhhhhhhhccccchhhhcccccccccccccccccchhhhhhhhhhhhhhhhccchhhhhccccccccccceeeecceeeeccccchhhhhhhhhhhhhhhhhhcccccccccccccccc'),\n",
              " ('HWGYGKHDGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKPLSVSYDQATSLRILNDGHAFNVEFDDSEDKAVLKGGPLDGTYRLIQFHFHWGSLDGEGSQHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPPLLECVTWIVLKEPISVSSEQVLKFRKLNFDGEGEPEELMVDNWRPAQPLKNRQIKASF',\n",
              "  'cccccccccccccccccccccccccccceeccccccccccccceeeeccccccceeeecccceeeecccccccceeeecccccceeeeeeeeeecccccccccceecccccceeeeeeeeeccccchhhhcccccceeeeeeeeeeeccchhhhhhhccccccccccceeecccccccccccccccceeceecccccccccceeeeecccceeeehhhhhhhcccccccccccccccccccccccccccccceecc')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creation de la fenetre glissante et encodages des labels\n"
      ],
      "metadata": {
        "id": "_wqeRYF21tfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from itertools import product\n",
        "\n",
        "# Constantes\n",
        "WINDOW_SIZE = 13\n",
        "AA_LIST = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "AA_TO_INDEX = {aa: i for i, aa in enumerate(AA_LIST)}\n",
        "SS_TO_INDEX = {'c': 0, 'h': 1, 'e': 2}\n",
        "NUM_AA = len(AA_LIST)\n",
        "\n",
        "# --- Fonction d'encodage one-hot ---\n",
        "#Transforme une acide aminé en un vecteur binaire de taille 20, la position correspondant a l'acide est un et le reste c'est 0\n",
        "def one_hot_encode(aa: str) -> torch.Tensor:\n",
        "    vec = torch.zeros(NUM_AA)\n",
        "    if aa in AA_TO_INDEX:\n",
        "        vec[AA_TO_INDEX[aa]] = 1.0\n",
        "    return vec\n",
        "\n",
        "\n",
        "def get_param_combinations(param_grid):\n",
        "    keys = param_grid.keys()\n",
        "    values = param_grid.values()\n",
        "    for combo in product(*values):\n",
        "        yield dict(zip(keys, combo))\n",
        "\n",
        "# --- Dataset personnalisé ---\n",
        "class ProteinDataset(Dataset):\n",
        "#Cree un dataset où chaque echantillon est une fenetre glissante autour d'un acide aminé\n",
        "    def __init__(self, sequences, structures, window_size=13, mode='one_hot', embedding_dim=None):\n",
        "        self.samples = []\n",
        "        self.mode=mode\n",
        "        self.embedding_dim=embedding_dim\n",
        "        self.window_size=window_size\n",
        "        pad = WINDOW_SIZE // 2\n",
        "        #le padding permet de centrer la fenetre autour de tous les acides aminés\n",
        "        for seq, ss in zip(sequences, structures):\n",
        "            seq = pad * 'X' + seq + pad * 'X'\n",
        "            ss = 'c' * pad + ss + 'c' * pad\n",
        "            for i in range(pad, len(seq) - pad):\n",
        "                window = seq[i - pad: i + pad + 1]\n",
        "                if 'X' in window:\n",
        "                    continue\n",
        "                encoded = torch.stack([one_hot_encode(aa) for aa in window])\n",
        "                label = SS_TO_INDEX.get(ss[i].lower(), 0)\n",
        "                self.samples.append((encoded, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "# --- MLP ---\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        #1ere couche cachée\n",
        "        self.fc1 = nn.Linear(WINDOW_SIZE * NUM_AA, 128) #Entrée la fenetre glissante one hot (13*20),sortie 128 neurones\n",
        "        self.bn1 = nn.BatchNorm1d(128) #application de la batchNorm\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "\n",
        "        #2eme couche cachée\n",
        "        self.fc2 = nn.Linear(128, 64) #reduction a 64 neurones\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.drop2 = nn.Dropout(0.3)\n",
        "\n",
        "        #derniere couche\n",
        "        self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n",
        "        return F.log_softmax(self.fc3(x), dim=1)#réduit a 3 sorties c,h,e\n",
        "\n",
        "# --- LSTM ---\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=NUM_AA, hidden_size=64, batch_first=True)\n",
        "        self.bn = nn.BatchNorm1d(64)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        h = self.bn(hn[-1])\n",
        "        h = self.drop(h)\n",
        "        return F.log_softmax(self.fc(h), dim=1)\n",
        "\n",
        "# Prochaine étape : entraînement et test des modèles\n",
        "\n"
      ],
      "metadata": {
        "id": "feQcB6g4ihmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training du modele"
      ],
      "metadata": {
        "id": "VoRqyLxwBjGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#Creation de l'optimizer Adam qui ajuste les poids d'un modele\n",
        "\n",
        "#Entrainement du modele\n",
        "def train_model(model,train_loader,optimizer,device):\n",
        "# Entraînement simple\n",
        "  for epoch in range(1, 10):\n",
        "      model.train()\n",
        "      for x, y in train_loader:\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          optimizer.zero_grad()#Reinitialise les gradients a chaque batch\n",
        "          loss = F.nll_loss(model(x), y)#Calcule de la loss\n",
        "          loss.backward()#backpropagation\n",
        "          optimizer.step()#mise a jour des poids\n",
        "      print(f\"Epoch {epoch} terminée.\")\n",
        "\n",
        "# Test\n",
        "def evaluate(model, test_loader, device):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for x, y in test_loader:\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          pred = model(x).argmax(dim=1)\n",
        "          correct += pred.eq(y).sum().item()\n",
        "\n",
        "  print(f\"Test accuracy: {100. * correct / len(test_dataset):.2f}%\")\n"
      ],
      "metadata": {
        "id": "PiT9eeOVixyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applications des hyper parametres"
      ],
      "metadata": {
        "id": "VYzEBtfBwxXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def get_param_combinations(param_grid):\n",
        "    keys = param_grid.keys()\n",
        "    values = param_grid.values()\n",
        "    for combo in product(*values):\n",
        "        yield dict(zip(keys, combo))\n",
        "\n",
        "def grid_search(train_data, test_data, param_grid):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    results = []\n",
        "\n",
        "    for params in get_param_combinations(param_grid):\n",
        "        print(f\"\\nTesting: {params}\")\n",
        "        train_dataset = ProteinDataset(*train_data, window_size=params['window_size'], mode=params['embedding_mode'], embedding_dim=params['embedding_dim'])\n",
        "        test_dataset = ProteinDataset(*test_data, window_size=params['window_size'], mode=params['embedding_mode'], embedding_dim=params['embedding_dim'])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=128)\n",
        "\n",
        "        input_size = len(AA_LIST) if params['embedding_mode'] == 'one_hot' else params['embedding_dim']\n",
        "\n",
        "        if params['model_type'] == 'MLP':\n",
        "            model = MLP().to(device)\n",
        "        else:\n",
        "            model = LSTM(input_size).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5) if params['sched'] else None\n",
        "\n",
        "        for epoch in range(5):\n",
        "            train_model(model, train_loader, optimizer, device)\n",
        "\n",
        "        acc = evaluate(model, test_loader, device)\n",
        "        print(f\"Accuracy: {acc:.2f}%\")\n",
        "        results.append((params, acc))\n",
        "\n",
        "    return results\n",
        "\n",
        "# grille d'hyperparametre\n",
        "param_grid = {\n",
        "    \"model_type\": [\"MLP\", \"RNN\"],\n",
        "    \"embedding_mode\": [\"one_hot\"],\n",
        "    \"sched\": [True],\n",
        "    \"window_size\": [5, 13],\n",
        "    \"embedding_dim\": [8],\n",
        "    \"batch_size\": [4],\n",
        "    \"lr\": [1e-2],\n",
        "    \"weight_decay\": [0.1],\n",
        "}\n",
        "\n",
        "train_sequences, train_labels = parse_protein_file(\"/content/protein-secondary-structure.train\")\n",
        "test_sequences, test_labels = parse_protein_file(\"/content/protein-secondary-structure.test\")\n",
        "results = grid_search((train_sequences, train_labels), (test_sequences, test_labels), param_grid)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "2LkxY3l_jrA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60eb4843-df39-436a-b7a2-929ef165f89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing: {'model_type': 'MLP', 'embedding_mode': 'one_hot', 'sched': True, 'window_size': 5, 'embedding_dim': 8, 'batch_size': 4, 'lr': 0.01, 'weight_decay': 0.1}\n",
            "Epoch 1 terminée.\n",
            "Epoch 2 terminée.\n",
            "Epoch 3 terminée.\n",
            "Epoch 4 terminée.\n",
            "Epoch 5 terminée.\n",
            "Epoch 6 terminée.\n",
            "Epoch 7 terminée.\n",
            "Epoch 8 terminée.\n",
            "Epoch 9 terminée.\n",
            "Epoch 1 terminée.\n",
            "Epoch 2 terminée.\n",
            "Epoch 3 terminée.\n",
            "Epoch 4 terminée.\n",
            "Epoch 5 terminée.\n",
            "Epoch 6 terminée.\n",
            "Epoch 7 terminée.\n",
            "Epoch 8 terminée.\n",
            "Epoch 9 terminée.\n",
            "Epoch 1 terminée.\n",
            "Epoch 2 terminée.\n",
            "Epoch 3 terminée.\n",
            "Epoch 4 terminée.\n",
            "Epoch 5 terminée.\n",
            "Epoch 6 terminée.\n",
            "Epoch 7 terminée.\n",
            "Epoch 8 terminée.\n",
            "Epoch 9 terminée.\n",
            "Epoch 1 terminée.\n",
            "Epoch 2 terminée.\n",
            "Epoch 3 terminée.\n",
            "Epoch 4 terminée.\n",
            "Epoch 5 terminée.\n",
            "Epoch 6 terminée.\n",
            "Epoch 7 terminée.\n",
            "Epoch 8 terminée.\n",
            "Epoch 9 terminée.\n",
            "Epoch 1 terminée.\n",
            "Epoch 2 terminée.\n",
            "Epoch 3 terminée.\n",
            "Epoch 4 terminée.\n",
            "Epoch 5 terminée.\n",
            "Epoch 6 terminée.\n",
            "Epoch 7 terminée.\n",
            "Epoch 8 terminée.\n",
            "Epoch 9 terminée.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0fa0e1fab237>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_protein_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/protein-secondary-structure.train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_protein_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/protein-secondary-structure.test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0fa0e1fab237>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(train_data, test_data, param_grid)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d755d7928bca>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test accuracy: {100. * correct / len(test_dataset):.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4ydYfIrw3N_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}